# FastAPI ML Inference Server

A ML Inference server example using FastAPI. Inspired by the PyTorch deployment docs. [Link](https://pytorch.org/tutorials/intermediate/flask_rest_api_tutorial.html#integrating-the-model-in-our-api-server)

## How to Run
```
pip install -r requirements.txt
uvicorn main:app --reload
```